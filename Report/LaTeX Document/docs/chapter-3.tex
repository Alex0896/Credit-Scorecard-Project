\chapter{Data} \label{cha:chapter-2}

The data I am using for this project is a collection of observations of 5, 960 home equity loans which is provided by Baesens,  Bart,  Roesch,  Daniel and Scheule,  Harald \cite{baesens2016credit}. Home equity loans are when an applicant borrows agains the value or 'equity' of their home. You can find a full description of each variable in Table (\ref{MetaData}).

\begin{figure}[ht]\label{Table2}
	\centering
	\renewcommand{\arraystretch}{1.5}
	\begin{tabular}{l p{10cm}}
	\hline
	Variable & \multicolumn{1}{c}{Definition}\\ 
	\hline
	BAD & 1 = Applicant defaulted on loan or seriously delinquent; 0 = applicant pain load \\
	LOAN & Amount of requested loan \\
	MORTDUE & Amount due on exisiting mortgage \\
	VALUE & Value of property the loan is to go against \\
	REASON & The reason the applicant is applying for the loan. DebtCon = Debt condsolidation; HomeImp = Home Improvement \\
	JOB & Occupational categories \\
	YOJ & Years at present job \\
	DEROG & Number of major derogatory reports \\
	DELINQ & Number of delinquent credit lines \\
	CLAGE & Age of oldest credit line in months \\
	NINQ & Number of recent credit inquiries \\
	CLNO & Number of credit lines \\
	DEBTINC & Debt-to-income ratio \\
	\end{tabular}
	\caption{Variables used in the Data Set \cite{baesens2016credit} \label{MetaData}}
\end{figure}

\section{Data Cleaning}

The data provided needed some initial cleaning. 2596 observations were missing atleast one value with some missing several variables. The biggest culprit of this would be DEBTINC with 1, 267 missing values. I decided to handle these missing values on a case by case basis applying different methods. First I decided to exclude observations missing more than a third of their variables,  339 fit this criteria. Next before I went forward with any imputing I considered any possible outliers within my numerical data,  using the summary table \ref{SUM_BFR_TBL}. You can see for the quantile ranges that there will most likely be some outliers occuring in the majority of the numerical variables. To solve this I removed the 99th percentile for every numerical variable excluding BAD,  this ended up removing 589 rows. \\

Moving onto imputing variable,  for MORTDUE and VALUE I imputed their values using a simple linear regression of the other. This was going on the assumption that the mortgage due on a house has a strong relationship with the value of property. The assumption is further backed up with the correlation between the two being 0.8748 before imputing,  far higher than any of the other correlations in the data.  So for MORTDUE I used Equation (\ref{MORTDUE_IMPUTE}) and for VALUE I used Equation (\ref{VALUE_IMPUTE}). This was applied to any missing value where the other was present and for the remaining I took the mean of each variable from the original data before the imputations.

\begin{equation}\label{MORTDUE_IMPUTE}
\text{MORTDUE} = \beta_{0} + \beta_{1}\text{VALUE}
\end{equation}

\begin{figure}[ht]\label{MORTDUE_IMPUTE_COEFS}
	\centering
	\begin{tabular}{lr}
	\hline
	$\beta_{0}$ & -2145.6497 \\
	$\beta_{1}$ & 0.7177 \\
	\hline
	\end{tabular}
\end{figure}

\begin{equation}\label{VALUE_IMPUTE}
\text{VALUE} = \beta_{0} + \beta_{1}\text{MORTDUE}
\end{equation}

\begin{figure}[ht]\label{VALUE_IMPUTE_COEFS}
	\centering
	\begin{tabular}{lr}
	\hline
	$\beta_{0}$ & 21340.4803 \\
	$\beta_{1}$ & 1.1253 \\
	\hline
	\end{tabular}
\end{figure}

For the remaining numerical variables excluding DEBTINC I chose to take the median of the values as there were only a small amount missing from each with no highly correlated variables to take a regression from. There is an argument that because DEBTINC is missing 991 (19.7 \%) that some other method from using the median value should be used. After some further analysis the decsion to drop the variable was made,  imputing did not appear to be an option as of the 857 bad applicants,  585 (68.2\%) of them were missing DEBTINC compared to 4175 and 405 (9.7\%) for good applicants. Dropping every row with DEBTINC did not appear to be practical either as it would result in the loss of almost 70\% of the bad applicants and their data whilst also taking the bad rate down to 6\%. Dropping DEBTINC would be the lower loss of information agains the alternative of dropping missing rows (5032 values lost vs 11892). \\

Last was the two categorical variables REASON ( DebtCon,  HomeImp ) and JOB ( Other,  Office,  Sales,  Mgr,  ProfExe,  Self ). REASON's categories were specified in the data dictionary but JOB's categories were not,  for simplicity I am going to assume that the missing values are of the categories just specified. Their missing values were 138 and 127 respectively and I decided to impute these values using a weighted random sample with the weights being the counts of the respective category. Below is two table summarizing the imputes,  I applied a seed to reproduce the sampling to remian consistent. \\

\begin{figure}[ht]\label{REASON_IMPUTES}
	\centering
	\renewcommand{\arraystretch}{1.25}
	\begin{tabular}{lrrrr}
	\multicolumn{5}{c}{REASON}\\
	\hline
	Category & \multicolumn{1}{c}{Original} & \multicolumn{1}{c}{Weight For Sampling} & \multicolumn{1}{c}{New} & \multicolumn{1}{c}{Count Imputed} \\ 
	\hline
	DebtCon & 3448 & 0.7005 & 3528 & 80\\
	HomeImp & 1474 & 0.2995 & 1504  & 30\\
	\end{tabular}
\end{figure}

\begin{figure}[ht]\label{JOB_IMPUTES}
	\centering
	\renewcommand{\arraystretch}{1.25}
	\begin{tabular}{lrrrr}
	\multicolumn{5}{c}{JOB}\\
	\hline
	Category & \multicolumn{1}{c}{Original} & \multicolumn{1}{c}{Weight For Sampling} & \multicolumn{1}{c}{New} & \multicolumn{1}{c}{Count Imputed} \\ 
	\hline
	Other & 2056 & 0.4175 & 2100 & 44 \\
	ProfExe & 1123 & 0.2281 & 1150 & 27 \\
	Office & 862 & 0.1751 & 877 & 15 \\
	Mgr & 646 & 0.1312 & 657  & 11 \\
	Self & 144 & 0.0292 & 151  & 7 \\
	Sales & 93 & 0.0189 & 97 & 4 \\
	\end{tabular}
\end{figure}

With these two completed I had no more missing values an no other noticeable issues which needed to be corrected before I could further look into the variables. A summary of actions taken on missing values can be found in table (\ref{DataCleanSummary}) \\

\begin{figure}[ht]\label{data_clean}
	\centering
	\renewcommand{\arraystretch}{1.25}
	\begin{tabular}{l r p{9cm}}
	\hline
	Variable & \multicolumn{1}{c}{No. Missing} & \multicolumn{1}{c}{Solution}\\ 
	\hline
	BAD & 0 & N/A\\
	LOAN & 0 & N/A \\
	MORTDUE & 316 & Imputed from a linear regression (\ref{MORTDUE_IMPUTE}). Mean taken when VALUE was unavailable \\
	VALUE & 59 & Imputed from a linear regression (\ref{VALUE_IMPUTE}). Mean taken when MORTDUE was unavailable \\
	REASON & 110 & Random weighted sample taken \\
	JOB & 108 & Random weighted sample taken \\
	YOJ & 311 & Median taken\\
	DEROG & 362 & Median taken \\
	DELINQ & 246 & Median taken\\
	CLAGE & 67 & Median taken \\
	NINQ & 178 & Median taken\\
	CLNO & 0 & N/A \\
	DEBTINC & 991 & Variable dropped as too much information missing\\
	\end{tabular}
	\caption{Missing Variables Breakdown \label{DataCleanSummary}}
\end{figure}

\section{Variables}

With data cleaned the remaining observations was 5032 of 12 independ variables with no missing values. A summary of the numerical values can be found in Table (\ref{SUM_AFT_TBL}). There you can see the remaining data has a bad rate of 17\% which equates to 857 defaulted applicants.

\subsection*{LOAN}

LOAN,  the amount requested for the home equity loan by the applicant can be seen in Figure (\ref{loan_dist}). The initial assumption was that higher loan values would have a higher bad rate due to the larger amount to pay back,  increasing the length and difficulty for the applicant to pay back the loan. Looking at the figure this does not appear to be the case,  although small,  larger loans tend to be payed off more often. The reasons for this are unclear,  a couple suggested could be that since we do not know exactly how this data was gathered the case could be that for larger loans the bank/company offering these loans had higher cutoffs on their applicant scoring to prevent higher risks in higher potential loss causing a shift down in the bad rate. Another could be the arguement that larger requested loans are coming from owners of higher valued properties,  which could be the case when looking at the correlation table \ref{CORR_TBL}. A higher property value indicates a better economic status and less likely to default on a loan. It would be reasonable to expect this variable to have a significant effect on the credit score.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/loan_dist.pdf}
	\caption{Distribution of LOAN by BAD. \label{loan_dist}}
\end{figure}

\subsection*{MORTDUE}

MORTDUE,  the outstanding balance on the applicants existing mortgage. Assumption here would be similar to LOAN,  a higher outstanding balance on their mortgage mean a large amount of debt and an increased risk of defaulting due to the larger payments. Looking at figure (\ref{mortdue_dist}) you can see it does not follow this assumption,  again a small but clear difference in the distribution shows that applicants with a higher outstanding balance on their mortgage are less likely to default. Whatever the reason behind this is would most likely be the same as the reason behind LOAN.

\subsection*{VALUE}

VALUE,  the property of the applicants and the equity the loan is being put against. The same initial assumption being made with MORTDUE is also here,  a value of an applicants property is an indication of their economic status. An owner of a higher valued property should be able to payback a larger loan and less likely to default on smaller ones. From figure (\ref{value_dist}) there is a small visible effect of loan on their probability of defaulting.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/mortdue_dist.pdf}
	\caption{Distribution of MORTDUE by BAD. \label{mortdue_dist}}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/value_dist.pdf}
	\caption{Distribution of VALUE by BAD. \label{value_dist}}
\end{figure}

\subsection*{REASON}

REASON,  the reason for the applicant's request. There are only two categories as seen in \ref{reason_cat},  DebtCon,  the loan would be used for a debt consolidation. HomeImp,  the loan is being used for a home improvement. A breakdown of their splits between good and bad can be found in table (\ref{reason_count_tbl}). The two categories continue to have similar splits when they do not default but when they do default,  HomeImp's split increases by 5\%. Looking at this further in figure (\ref{reason_cat}) the bad rate for DebtCon is 15.87\% and HomeImp 19.75\%. Although there does appear to be a difference,  it is small and compared to other variables in the group I would expect this to be on the lower end of signifiance.

\begin{figure}[ht]
	\centering
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{lrrr}
		\toprule
		Category & \% of Total (N = 5032) & \% of Good (N = 4175) & \% of Bad (N = 857) \\
		\midrule
		DebtCon &  70.0\% (3528) & 71.1\% (2968) & 65.3\% (560)  \\
		HomeImp & 30.0\% (1504) & 28.9\% (1207) &  34.7\% (297)  \\
		\bottomrule
	\end{tabular}
	\caption{REASON breakdown \label{reason_count_tbl}}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/reason_cat.pdf}
	\caption{Category plot of REASON by BAD. \label{reason_cat}}
\end{figure}

\subsection*{JOB}

JOB,  categorical job occupation. Categories can be seen in \ref{job_cat}. Occupation could be used as an indicator for the applicants economic status e.g. a ProfExe,  proffesional executive is more likely to have a higher income than office staff or someone who is self employed. It could also be used to see how volatile their employement status is,  someone who is self employed can be seen as a possible risk due to their income being potentially unstable. Although we do not have a way of looking at their job security,  we do have YOJ,  years at present job,  as an indicator of Job security. Comparing figure (\ref{job_yoj_cat}) and figure (\ref{job_cat}),  Sales,  the job with the lowest average YOJ has the highest bad rate at 30.93\% followed by Self at 22.52\%. 

\begin{figure}[ht]
	\centering
	\renewcommand{\arraystretch}{2}
	\begin{tabular}{lrrr}
		\toprule
		Category & \% of Total (N = 5032) & \% of Good (N = 4175) & \% of Bad (N = 857) \\
		\midrule
		Other & 41.7\% (2100) & 40.0\% (1672) &  49.9\% (428)  \\
		ProfExe & 22.9\% (1150) & 24.0\% (1004) &  17.0\% (146)  \\
		Office & 17.4\% (877) & 18.9\% (787) &  10.5\% (90)  \\
		Mgr &  13.1\% (657) & 12.6\% (528) & 15.1\% (129)  \\
		Self & 3.0\% (151) & 2.8\% (117) &  4.0\% (34)  \\
		Sales & 1.9\% (97) & 1.6\% (67) &  3.5\% (30)  \\
		\bottomrule
	\end{tabular}
	\caption{JOB breakdown \label{job_count_tbl}}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/job_cat.pdf}
	\caption{Category plot of JOB by BAD. \label{job_cat}}
\end{figure}

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/job_yoj_cat.pdf}
	\caption{Category plot of JOB by mean of YOJ. \label{job_yoj_cat}}
\end{figure}

\subsection*{YOJ}

YOJ,  number of years the applicant has been at present job. Can be an indicator of job security,  an applicant losing their job can be a high risk of defaulting on their loan. Figure (\ref{yoj_dist} shows that the majority of applicants are between 3 to 14 years at their current job with the mean for bads and goods being relatively the same. The difference between them starts to become noticable at higher values where an applicant who has been at their present job for more than 20 years starts to become less likely to default.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/yoj_dist.pdf}
	\caption{Distribution of YOJ by BAD. \label{yoj_dist}}
\end{figure}

\subsection*{DEROG}

DEROG,  number of dergoatory marks on aginast the applicant. A derogatory mark can have a large impact on your chances of being accepted for a loan. In this dataset,  only 12.3\% of applicants have 1 or more dergoatory mark. An applicant can recieve a derogatory mark for various reasons such as,  missing payments,  bankruptcy,  repossession,  etc. The severity of the reason for the derogatory mark is often used in credit scoring but for this dataset we only have the numbers of marks against the applicant. Figure (\ref{derog_cat}) shows the impact having a derogatory mark can have on your chance of defaulting with 0 having a bad rate of 14.3\% and 3 having a bad rate of 65.91\%.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/derog_cat.pdf}
	\caption{Category plot of DEROG by BAD. \label{derog_cat}}
\end{figure}

\subsection*{DELINQ}

DELINQ,  Number of delinquent credit lines. Delinquency is used to describe when a borrower has missed a payment,  the borrower is referred to as delinquent. Delinquency preceeds defaulting,  once a borrower has been deqlinquent for a time it comes apparent that the borrower is unable to pay back the loan. The data we are provided is the number of deqlinquent credit lines,  which is the number of credit lines the borrower has missed payments on. 

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/delinq_cat.pdf}
	\caption{Category plot of DELINQ by BAD. \label{delinq_cat}}
\end{figure}

\subsection*{CLAGE}

CLAGE,  Age of oldest credit line in months. Assumption here is the longer an applicant has held credit lines the more experienced they are in repaying payments. A applicant who has experience in credit repayments for 20 years is going to have a better time in avoiding delinqency and defaulting that someone who is new to credit. Figure (\ref{clage_dist}) reinforces this assumption,  there is a clear difference in the distributions of goods and bads. Applicants between 100 and 150 months on thier oldest credit line have a bad rate of 21.8\% and applicants between 200 and 300 have a bad rate of 9.5\%. Expecting this value to have a strong signifance for the credit score.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/clage_dist.pdf}
	\caption{Distribution of CLAGE by BAD. \label{clage_dist}}
\end{figure}

\subsection*{NINQ}

NINQ,  number of recent credit inquiries. Figure (\label{ninq_cat}) indicates that the more recent credit equiries an applicant makes the more likely they are to default,  this trend is followed until the higher values are reached but this deviation could be due to the low sample size at larger values. 73.8\% of applicants have made no more than 1 recent credit equiry where as only 3\% of applicants made 5 or more. This could create an issue depending on how the WOE method bins the values.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/ninq_cat.pdf}
	\caption{Category plot of NINQ by BAD. \label{ninq_cat}}
\end{figure}

\subsection*{CLNO}

CLNO,  number of credit lines. A credit line can be any method in which someone can recieve credit such as an overdraft,  credit card,  etc. Figure (\ref{clno_dist}) suggests that applicants with low or high values for credit lines have a higher bad rate that ones in the centre. A reason behind this could be that a applicant with a low number of credit lines could be inexperience with debt management or don't have access to other credit to ensure payment on loans is on time. On the other end it could be that applicants with a large number of credit lines become incapable of managing the potential debt from the numerous sources. Where as the centre is seen to be where applicants have a good control over their credit lines. Applicants with a CLNO value between 20 and 30 have a bad rate of 15.1\% where applicants outside of this group have a bad rate of 23.1\%. A differnce of 8\%.

\begin{figure}[!ht]
	\centering
	\includegraphics[scale=0.40]{figs/clno_dist.pdf}
	\caption{Distribution of CLNO by BAD. \label{clno_dist}}
\end{figure}

\section{WOE and IV}

WOE binning and calculation was done using the scorecardpy package provided by ShichenXie \cite{scorecardpy},  results can be found in the two tables (\ref{woe_1}) \& (\ref{woe_2}). I allowed the function to determine optimal bins itself using the chimerge method described in Section \ref{chimerge}. In the table we have a breakdown for each bin providing their woe value and individual information values. We can also see the total information value of each variable in the last column (total\_iv). Based on IV,  our strongest predictor by a large margin is DELINQ with a IV value of 0.47 and our weakest is Reason with an IV of 0.02. Referring back to Bailey's guideline (\ref{IV})\cite{bailey2004credit}, we can categorise each variable on their strength from the IV.\\

Looking back on our data exploration we can see that our assumption about some of the variables appear to be reflecting in the WOE bins. Reason, a variable I expected to be rather insignifcant due to the bad rate being similar in both categories has the lowest IV. NINQ appears to have been binned appropriately with the upper bin being [4.0, inf) meaning the drop in bad rate at 7.0, assumed to be from a small sample, should not have a siginicant effect on the woe value of the group. The assumption on CLAGE, the variable with the second highest IV, is also reflected in the WOE values with a clear trend appearing in the bad probabilities of each bin seen in figure (\ref{fig:ClageWoe}).

\begin{figure}[ht]\label{Table2}
	\centering
	\renewcommand{\arraystretch}{1.25}
	\begin{tabular}{llr}
	\multicolumn{3}{c}{Variables Prediction Strength}\\
	\hline
	Variable & \multicolumn{1}{c}{Strength} & IV\\ 
	\hline
	LOAN & Average & 0.25\\
	MORTDUE & Average & 0.10\\
	VALUE & Average & 0.20\\
	REASON & Poor & 0.02\\
	JOB & Average & 0.12\\
	YOJ & Weak & 0.07\\
	DEROG & Average & 0.23\\
	DELINQ & Strong & 0.47\\
	CLAGE & Average & 0.28\\
	NINQ & Average & 0.12\\
	CLNO & Average & 0.12\\
	\bottomrule
	\end{tabular}
\end{figure}

\begin{figure}
\centering
  \centering
  \includegraphics[width=0.9\linewidth]{figs/ninq_woe_plot.png}
  \caption{NINQ woe plot}
  \label{fig:NinqWoe}
\end{figure}

\begin{figure}
  \centering
 \includegraphics[width=0.9\linewidth]{figs/clage_woe_plot.png}
  \caption{Clage woe plot}
  \label{fig:ClageWoe}
\end{figure}

\begin{landscape}
	\begin{figure}[!ht]
		\centering
		\begin{tabular}{lllrrrrrrrr}
			\toprule
			variable & bin &  count &  count\_distr &  good &  bad &   badprob &       woe &    bin\_iv &  total\_iv \\
			\midrule
			    LOAN &      [-inf, 6000.0) &    254 &         0.05 &   136 &  118 &     0.46 &  1.44 &    0.15 &      0.25 \\
			     &    [6000.0, 8000.0) &    270 &         0.05 &   204 &   66 &     0.24 &  0.45 &    0.01 &      0.25 \\
			     &   [8000.0, 11000.0) &    678 &         0.13 &   546 &  132 &     0.19 &  0.16 &    0.00 &      0.25 \\
			     &  [11000.0, 15000.0) &    936 &         0.19 &   790 &  146 &     0.16 & -0.10 &    0.00 &      0.25 \\
			     &  [15000.0, 16000.0) &    312 &         0.06 &   245 &   67 &     0.21 &  0.29 &    0.01 &      0.25 \\
			     &  [16000.0, 21000.0) &   1006 &         0.20 &   879 &  127 &     0.13 & -0.35 &    0.02 &      0.25 \\
			     &  [21000.0, 25000.0) &    597 &         0.12 &   541 &   56 &     0.09 & -0.68 &    0.04 &      0.25 \\
			     &      [25000.0, inf) &    979 &         0.19 &   834 &  145 &     0.15 & -0.17 &    0.01 &      0.25 \\
			\midrule
			  MORTDUE &       [-inf, 35000.0) &    835 &         0.17 &   621 &  214 &     0.26 &  0.52 &    0.05 &       0.1 \\
			  &    [35000.0, 55000.0) &   1172 &         0.23 &   960 &  212 &     0.18 &  0.07 &    0.00 &       0.1 \\
			  &    [55000.0, 60000.0) &    355 &         0.07 &   309 &   46 &     0.13 & -0.32 &    0.01 &       0.1 \\
			  &    [60000.0, 75000.0) &    892 &         0.18 &   742 &  150 &     0.17 & -0.02 &    0.00 &       0.1 \\
			  &   [75000.0, 105000.0) &   1048 &         0.21 &   917 &  131 &     0.12 & -0.36 &    0.02 &       0.1 \\
			  &  [105000.0, 130000.0) &    348 &         0.07 &   289 &   59 &     0.17 & -0.01 &    0.00 &       0.1 \\
			  &       [130000.0, inf) &    382 &         0.08 &   337 &   45 &     0.12 & -0.43 &    0.01 &       0.1 \\
			\midrule
			    VALUE &       [-inf, 50000.0) &    488 &         0.10 &   318 &  170 &     0.35 &  0.96 &    0.12 &       0.2 \\
			    &    [50000.0, 70000.0) &    998 &         0.20 &   835 &  163 &     0.16 & -0.05 &    0.00 &       0.2 \\
			    &    [70000.0, 80000.0) &    529 &         0.11 &   422 &  107 &     0.20 &  0.21 &    0.01 &       0.2 \\
			    &   [80000.0, 125000.0) &   1952 &         0.39 &  1694 &  258 &     0.13 & -0.30 &    0.03 &       0.2 \\
			    &  [125000.0, 175000.0) &    619 &         0.12 &   499 &  120 &     0.19 &  0.16 &    0.00 &       0.2 \\
			    &       [175000.0, inf) &    446 &         0.09 &   407 &   39 &     0.09 & -0.76 &    0.04 &       0.2 \\
			\midrule
			    REASON &  DebtCon &   3528 &          0.7 &  2968 &  560 &     0.16 & -0.08 &    0.00 &      0.02 \\
 				  &  HomeImp &   1504 &          0.3 &  1207 &  297 &     0.20 &  0.18 &    0.01 &      0.02 \\
			\midrule
			       JOB &    Other &   2100 &         0.42 &  1672 &  428 &     0.20 &  0.22 &    0.02 &      0.12 \\
			      &   Office &    877 &         0.17 &   787 &   90 &     0.10 & -0.58 &    0.05 &      0.12 \\
			      &    Sales &     97 &         0.02 &    67 &   30 &     0.31 &  0.78 &    0.01 &      0.12 \\
			      &      Mgr &    657 &         0.13 &   528 &  129 &     0.20 &  0.17 &    0.00 &      0.12 \\
			      &  ProfExe &   1150 &         0.23 &  1004 &  146 &     0.13 & -0.34 &    0.02 &      0.12 \\
			      &     Self &    151 &         0.03 &   117 &   34 &     0.23 &  0.35 &    0.00 &      0.12 \\
			
			\bottomrule
		\end{tabular}
		\caption{WOE results table. \label{woe_1}}
	\end{figure}
	
	\begin{figure}[!ht]
		\centering
		\begin{tabular}{lllrrrrrrrr}
			\toprule
			variable & bin &  count &  count\_distr &  good &  bad &   badprob &       woe &    bin\_iv &  total\_iv \\
			\midrule
			     YOJ &   [-inf, 2.0) &    750 &         0.15 &   615 &  135 &     0.18 &  0.07 &    0.00 &      0.07 \\
			      &    [2.0, 6.0) &   1190 &         0.24 &   935 &  255 &     0.21 &  0.28 &    0.02 &      0.07 \\
			      &   [6.0, 12.0) &   1729 &         0.34 &  1467 &  262 &     0.15 & -0.14 &    0.01 &      0.07 \\
			      &  [12.0, 21.0) &    918 &         0.18 &   750 &  168 &     0.18 &  0.09 &    0.00 &      0.07 \\
			      &   [21.0, inf) &    445 &         0.09 &   408 &   37 &     0.08 & -0.82 &    0.04 &      0.07 \\
			\midrule
			 DEROG &  [-inf, 1.0) &   4482 &         0.89 &  3841 &  641 &     0.14 & -0.21 &    0.04 &      0.23 \\
  			  &   [1.0, inf) &    550 &         0.11 &   334 &  216 &     0.39 &  1.15 &    0.20 &      0.23 \\
			\midrule
			  DELINQ &  [-inf, 1.0) &   4086 &         0.81 &  3595 &  491 &     0.12 & -0.41 &    0.12 &      0.47 \\
			   &   [1.0, 2.0) &    553 &         0.11 &   372 &  181 &     0.33 &  0.86 &    0.11 &      0.47 \\
			   &   [2.0, inf) &    393 &         0.08 &   208 &  185 &     0.47 &  1.47 &    0.24 &      0.47 \\
			\midrule
			   CLAGE &    [-inf, 70.0) &    266 &         0.05 &   169 &   97 &     0.36 &  1.03 &    0.07 &      0.28 \\
			    &   [70.0, 150.0) &   1858 &         0.37 &  1435 &  423 &     0.23 &  0.36 &    0.05 &      0.28 \\
			    &  [150.0, 180.0) &    691 &         0.14 &   573 &  118 &     0.17 &  0.00 &    0.00 &      0.28 \\
			    &  [180.0, 240.0) &   1183 &         0.24 &  1047 &  136 &     0.11 & -0.46 &    0.04 &      0.28 \\
			    &    [240.0, inf) &   1034 &         0.21 &   951 &   83 &     0.08 & -0.86 &    0.11 &      0.28 \\
			\midrule
			    NINQ &  [-inf, 2.0) &   3714 &         0.74 &  3178 &  536 &     0.14 & -0.20 &    0.03 &      0.12 \\
			     &   [2.0, 4.0) &   1034 &         0.21 &   815 &  219 &     0.21 &  0.27 &    0.02 &      0.12 \\
			     &   [4.0, inf) &    284 &         0.06 &   182 &  102 &     0.36 &  1.00 &    0.08 &      0.12 \\
			\midrule
			    CLNO &  [-inf, 10.0) &    496 &         0.10 &   339 &  157 &     0.32 &  0.81 &    0.08 &      0.12 \\
			     &  [10.0, 24.0) &   2763 &         0.55 &  2332 &  431 &     0.16 & -0.10 &    0.01 &      0.12 \\
			     &  [24.0, 27.0) &    600 &         0.12 &   537 &   63 &     0.10 & -0.56 &    0.03 &      0.12 \\
			     &   [27.0, inf) &   1173 &         0.23 &   967 &  206 &     0.18 &  0.04 &    0.00 &      0.12 \\
			\bottomrule
		\end{tabular}
		\caption{WOE results table. \label{woe_2}}
	\end{figure}
\end{landscape}